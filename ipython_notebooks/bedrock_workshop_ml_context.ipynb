{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.21",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "hide_input": false,
    "creator": "gus.cavanaugh@dataiku.com",
    "createdOn": 1759589599413,
    "customFields": {},
    "tags": [],
    "modifiedBy": "gus.cavanaugh@dataiku.com"
  },
  "nbformat": 4,
  "nbformat_minor": 5,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Source A Gulli\nhttps://docs.google.com/document/d/1GWShQ74DwZRUVs4e0yoS3rYmBxUVR-x4N_Xt5xl5dtE/edit?tab\u003dt.kivct9twtv3c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Traditional Programming -- Rule Based Classification"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# We define a function using the \u0027def\u0027 keyword.\n# This function takes one input, \u0027number\u0027.\ndef classify_number(number):\n    \"\"\"\n    This function takes a number and returns a string label:\n    \"small\", \"medium\", or \"large\" based on hand-written rules.\n    \"\"\"\n    print(f\"Analyzing the number: {number}\")\n\n    # The \u0027if\u0027 statement checks a condition.\n    # If the number is less than 10, the indented code below runs.\n    if number \u003c 10:\n        return \"small\"\n    \n    # \u0027elif\u0027 is short for \"else if\". It checks another condition.\n    elif number \u003c 100:\n        return \"medium\"\n    \n    # \u0027else\u0027 runs if none of the above conditions were true.\n    else:\n        return \"large\""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print (\"hello\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Now, let\u0027s test our function.\nresult1 \u003d classify_number(5)\nprint(f\"The result is: {result1}\")\n\nresult2 \u003d classify_number(50)\nprint(f\"The result is: {result2}\")\n\nresult3 \u003d classify_number(500)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Traditional Programming: Rule-based Clustering"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Here is our unlabeled list of words.\nwords \u003d [\"apple\", \"banana\", \"ant\", \"boat\", \"car\", \"cat\", \"anchor\"]\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "words"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# We will store our groups in a dictionary.\n# A dictionary stores key-value pairs, like {\"a\": [\"apple\", \"ant\"]}.\ngrouped_words \u003d {}\n\n# A \u0027for\u0027 loop lets us check every word in our list.\nfor word in words:\n    # Get the first letter of the current word.\n    first_letter \u003d word[0]\n    \n    # Check if we have already started a group for this letter.\n    if first_letter not in grouped_words:\n        # If not, create a new empty list for this letter.\n        grouped_words[first_letter] \u003d []\n    \n    # Add the current word to the group for its first letter.\n    grouped_words[first_letter].append(word)\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grouped_words"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Machine Learning -- Statiscal Model Classification"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\n\n# The Features (X): [Action Score, Comedy Score]\nX \u003d np.array([\n    [9, 2], [3, 8], [8, 1], [4, 9],  # Liked movies\n    [2, 1], [1, 3], [4, 2], [3, 3]   # Disliked movies\n])\n\n# The Labels (y): 1 for \"Liked\", 0 for \"Disliked\"\ny \u003d np.array([1, 1, 1, 1, 0, 0, 0, 0])"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "scrolled": true
      },
      "source": [
        "data \u003d {\u0027Action Score\u0027: X[:, 0], \u0027Comedy Score\u0027: X[:, 1], \"Sarah\u0027s Verdict\": y}\ndf \u003d pd.DataFrame(data)\ndf"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# The new, unknown movie we want to classify\nnew_movie \u003d np.array([7, 6])\nnew_movie"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How do we know what to classify it as?"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n# --- Visualization ---\nplt.figure(figsize\u003d(8, 6))\n\n# Plot the \"Liked\" movies in green\nplt.scatter(X[y \u003d\u003d 1, 0], X[y \u003d\u003d 1, 1], c\u003d\u0027green\u0027, marker\u003d\u0027o\u0027, label\u003d\u0027Liked\u0027)\n\n# Plot the \"Disliked\" movies in red\nplt.scatter(X[y \u003d\u003d 0, 0], X[y \u003d\u003d 0, 1], c\u003d\u0027red\u0027, marker\u003d\u0027x\u0027, label\u003d\u0027Disliked\u0027)\n\n# Plot the new movie as a blue star\nplt.scatter(new_movie[0], new_movie[1], c\u003d\u0027blue\u0027, marker\u003d\u0027*\u0027, s\u003d150, label\u003d\u0027New Movie\u0027)\n\nplt.title(\"Sarah\u0027s Movie Tastes\")\nplt.xlabel(\"Action Score\")\nplt.ylabel(\"Comedy Score\")\nplt.legend()\nplt.grid(True)\nplt.show()\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- The Three Magic Lines for KNN ---\n\n# 1. Import the model we want to use.\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# 2. Instantiate the model.\n# We choose K (the number of neighbors) to be 3.\nmodel \u003d KNeighborsClassifier(n_neighbors\u003d3)\n\n# 3. Fit the model to our data.\n# For KNN, this step simply memorizes the data\u0027s location.\nmodel.fit(X, y)\n\nprint(\"Training complete! The KNN model has stored the data.\")\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Our new movie data, reshaped for Scikit-learn\nnew_movie \u003d np.array([[7, 6]])\n\n# Use the trained model to make a prediction.\nprediction \u003d model.predict(new_movie)\n\n# Let\u0027s print the result in a user-friendly way.\nif prediction[0] \u003d\u003d 1:\n    print(\"Prediction: Sarah will LIKE this movie.\")\nelse:\n    print(\"Prediction: Sarah will DISLIKE this movie.\")\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# (This code assumes you have run the previous examples)\nfrom matplotlib.colors import ListedColormap\n\n# Create a color map for the background\ncmap_light \u003d ListedColormap([\u0027#FFCCCC\u0027, \u0027#CCFFCC\u0027]) # Red and Green background colors\n\n# Create a grid of points to classify\nx_min, x_max \u003d X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max \u003d X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy \u003d np.meshgrid(np.arange(x_min, x_max, 0.1),\n                     np.arange(y_min, y_max, 0.1))\n\n# Get predictions for every point on the grid\nZ \u003d model.predict(np.c_[xx.ravel(), yy.ravel()])\nZ \u003d Z.reshape(xx.shape)\n\n# --- Plot the Decision Boundary ---\nplt.figure(figsize\u003d(8, 6))\nplt.contourf(xx, yy, Z, cmap\u003dcmap_light)\n\n# Plot the original data points on top\nplt.scatter(X[y \u003d\u003d 1, 0], X[y \u003d\u003d 1, 1], c\u003d\u0027green\u0027, marker\u003d\u0027o\u0027, label\u003d\u0027Liked\u0027)\nplt.scatter(X[y \u003d\u003d 0, 0], X[y \u003d\u003d 0, 1], c\u003d\u0027red\u0027, marker\u003d\u0027x\u0027, label\u003d\u0027Disliked\u0027)\nplt.scatter(new_movie[0,0], new_movie[0,1], c\u003d\u0027blue\u0027, marker\u003d\u0027*\u0027, s\u003d150, label\u003d\u0027New Movie\u0027)\n\nplt.title(\"KNN Decision Boundary (K\u003d3)\")\nplt.xlabel(\"Action Score\")\nplt.ylabel(\"Comedy Score\")\nplt.legend()\nplt.grid(True)\nplt.show()\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}